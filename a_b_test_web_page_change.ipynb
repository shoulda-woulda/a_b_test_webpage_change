{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Influence of Color Alteration on Webpage Click Rates through A/B Testing\n",
    "\n",
    "A ficticious company called \"Quantum Dynamics Innovations, Inc.\" has a made a change to a prominent call-to-action (CTA) button which takes visitors to the contact page.\n",
    "\n",
    "__Original Design (A):__\n",
    "\n",
    "CTA button color: Blue\n",
    "\n",
    "__Variation (B):__\n",
    "\n",
    "CTA button color: Green\n",
    "\n",
    "**The goal is to determine if the color change significantly influences user behavior and whether it improves or hinders the clicks to the contact page.**\n",
    "\n",
    "A Bayesian approach will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Importing and cleaning the test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.stats import beta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of dataset\n",
      "   user_id                   timestamp      group landing_page  converted\n",
      "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
      "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
      "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
      "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
      "4   864975  2017-01-21 01:52:26.210827    control     old_page          1\n",
      "\n",
      " shape of dataset (rows, columns)\n",
      "(294478, 5)\n",
      "\n",
      " column names and datatypes\n",
      "user_id          int64\n",
      "timestamp       object\n",
      "group           object\n",
      "landing_page    object\n",
      "converted        int64\n",
      "dtype: object\n",
      "\n",
      " NaN values\n",
      "user_id         0\n",
      "timestamp       0\n",
      "group           0\n",
      "landing_page    0\n",
      "converted       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"First 5 rows of dataset\")\n",
    "a_b_test = pd.read_csv(\"data/ab_data.csv\")\n",
    "print(a_b_test.head())\n",
    "print(\"\\n\",\"shape of dataset (rows, columns)\")\n",
    "print(a_b_test.shape)\n",
    "print(\"\\n\",\"column names and datatypes\")\n",
    "print(a_b_test.dtypes)\n",
    "print(\"\\n\",\"NaN values\")\n",
    "print(a_b_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has no missing values and column names and datatypes are formatted correctly. To define the columns:\n",
    "\n",
    "- __user_id__ : This should be unique and show the first time a unique user_id visited the website by using a users cookies. __Each user should only belong to one group.__\n",
    "\n",
    "- __timestamp__: The time stamp that the user visited to page. \n",
    "\n",
    "- __group__: Whether the user is part of the control group (old page) or the treatment group (new page).\n",
    "\n",
    "- __landing_page__: Which page the user was shown, the old page (no change to button) or the new page (button changed to green).\n",
    "\n",
    "- __converted__: Whether the user clicked on the button to be taken to the contact details page. 1 for click, 0 for no-click.\n",
    "\n",
    "\n",
    "The user_id field will now be validated for unique-ness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate values in user_id\n",
      "        user_id                   timestamp      group landing_page  converted\n",
      "230259   630052  2017-01-17 01:16:05.208766  treatment     new_page          0\n",
      "213114   630052  2017-01-07 12:25:54.089486  treatment     old_page          1\n",
      "22513    630126  2017-01-14 13:35:54.778695  treatment     old_page          0\n",
      "251762   630126  2017-01-19 17:16:00.280440  treatment     new_page          0\n",
      "183371   630137  2017-01-20 02:08:49.893878    control     old_page          0\n",
      "\n",
      " How many duplicate values in user_id\n",
      "(7788, 5)\n",
      "\n",
      " % of entries that are for user_id's that have duplicates\n",
      "2.64\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicate values in user_id\")\n",
    "duplicate_user_id = a_b_test[a_b_test.duplicated(subset='user_id', keep=False)].sort_values(by='user_id')\n",
    "print(duplicate_user_id.head())\n",
    "\n",
    "print(\"\\n\",\"How many duplicate values in user_id\")\n",
    "print(duplicate_user_id.shape)\n",
    "\n",
    "print(\"\\n\",\"% of entries that are for user_id's that have duplicates\")\n",
    "print(round((duplicate_user_id.shape[0]/a_b_test.shape[0]),4)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These non-unique user_id's have entries where they are in one group, but have been shown both versions of the page. This goes against the control of this experiment and must have been done in error. In practice, only showing one version of a webpage is quite complicated and these errors happen.\n",
    "\n",
    "The first visit to the webpage for each user_id will be taken as golden truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate user_id values in cleaned dataset\n",
      "0\n",
      "\n",
      " how many weeks the experiment ran for?\n",
      "3.1428390904877643\n"
     ]
    }
   ],
   "source": [
    "a_b_test = a_b_test.drop_duplicates(subset='user_id', keep=False)\n",
    "\n",
    "user_ids_first_value = duplicate_user_id.loc[duplicate_user_id.groupby('user_id')['timestamp'].idxmin()]\n",
    "\n",
    "a_b_test = pd.concat([a_b_test,user_ids_first_value],axis=0)\n",
    "\n",
    "print(\"duplicate user_id values in cleaned dataset\")\n",
    "print(a_b_test[a_b_test.duplicated(subset='user_id', keep=False)].sort_values(by='user_id').shape[0])\n",
    "\n",
    "\n",
    "print(\"\\n\",\"how many weeks the experiment ran for?\")\n",
    "print((datetime.strptime(a_b_test[\"timestamp\"].max(), '%Y-%m-%d %H:%M:%S.%f') - datetime.strptime(a_b_test[\"timestamp\"].min(), '%Y-%m-%d %H:%M:%S.%f'))/ timedelta(weeks=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timestamp field will now be used to create a new field, \"week_of_experiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users that visited per week\n",
      "week\n",
      "2    92734\n",
      "3    91588\n",
      "1    85735\n",
      "4    20527\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "a_b_test['week'] = a_b_test['timestamp'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S.%f').isocalendar()[1])\n",
    "\n",
    "print(\"number of users that visited per week\")\n",
    "print(a_b_test['week'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control group: overall % split of click vs non click\n",
      "\n",
      " converted_category\n",
      "Did not click    87.92\n",
      "Clicked          12.08\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "\n",
      "Treatment group: overall % split of click vs non click\n",
      "\n",
      " converted_category\n",
      "Did not click    88.08\n",
      "Clicked          11.92\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "\n",
      "Before properly analysing it could be hypothesised that the experiment did not have a positive effect on proportion of users clicking the button, or that it even had a detrimental effect.\n"
     ]
    }
   ],
   "source": [
    "a_b_test['converted_category'] = a_b_test['converted'].apply(lambda x: 'Clicked' if x==1 else 'Did not click')\n",
    "\n",
    "data_control = a_b_test[(a_b_test['week']!=1) & (a_b_test['group']=='control')][['converted_category','converted']]\n",
    "data_treatment = a_b_test[(a_b_test['week']!=1) & (a_b_test['group']=='treatment')][['converted_category','converted']]\n",
    "\n",
    "print(\"Control group: overall % split of click vs non click\\n\\n\", round(a_b_test[(a_b_test['week']!=1) & (a_b_test['group']=='control')]['converted_category'].value_counts(normalize=True)*100,2))\n",
    "\n",
    "print(\"\\n\\nTreatment group: overall % split of click vs non click\\n\\n\", round(a_b_test[(a_b_test['week']!=1) & (a_b_test['group']=='treatment')]['converted_category'].value_counts(normalize=True)*100,2))\n",
    "\n",
    "print(\"\\n\\nBefore properly analysing it could be hypothesised that the experiment did not have a positive effect on proportion of users clicking the button, or that it even had a detrimental effect.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Analysing the Test Results\n",
    "\n",
    "A Bayesian approach to this analysis requires a _prior distribution_. For the purposes of this report the first week of experiment will be used to return the prior distribution. \n",
    "\n",
    "_In practice, this data would be provided before the experiment has begun._\n",
    "\n",
    "The first weeks data will be sampled randomly 10,000 times with 2,000 elements being taken each sample and a mean calculated. This mean will be appended to a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = a_b_test[(a_b_test['week'] == 1) & (a_b_test['group']=='control')]\n",
    "\n",
    "prior_means = []\n",
    "\n",
    "for i in range(10000):\n",
    "    prior_means.append(prior.sample(2000)['converted'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the beta.fit function the values for 'prior_alpha' and 'prior_beta' will be estimated.\n",
    "\n",
    "floc=0 and flac=1 are used to fix the location and the scale (respectively). This is because the beta distribution is defined in the interval [0,1] as we are dealing with mean conversion (we cannot have > 100% (or 1.0) conversion).\n",
    "\n",
    "For each week of experiment, the results will be calculated to show how each week effects the confidence and validaty of result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running the experiment for 1 weeks \n",
      " Probability that the treatment > control: 25.60% \n",
      " by this much lift: -1.20%\n",
      "Control Posterior: Mean: 0.120, Variance: 0.00000217\n",
      "Treatment Posterior: Mean: 0.118, Variance: 0.00000215\n",
      "\n",
      "Running the experiment for 2 weeks \n",
      " Probability that the treatment > control: 18.00% \n",
      " by this much lift: -1.20%\n",
      "Control Posterior: Mean: 0.121, Variance: 0.00000112\n",
      "Treatment Posterior: Mean: 0.119, Variance: 0.00000111\n",
      "\n",
      "Running the experiment for 2.14 weeks \n",
      " Probability that the treatment > control: 12.80% \n",
      " by this much lift: -1.40%\n",
      "Control Posterior: Mean: 0.121, Variance: 0.00000102\n",
      "Treatment Posterior: Mean: 0.119, Variance: 0.00000101\n"
     ]
    }
   ],
   "source": [
    "prior_alpha, prior_beta, _, _ = beta.fit(prior_means, floc=0, fscale=1)\n",
    "\n",
    "for i,week in enumerate(sorted(a_b_test['week'].unique()[a_b_test['week'].unique()>1])):\n",
    "    experiment_data = a_b_test[(a_b_test['week'] > 1) & (a_b_test['week'] <= week)]\n",
    "    control_data = experiment_data[experiment_data['group']=='control']['converted']\n",
    "    treatment_data = experiment_data[experiment_data['group']=='treatment']['converted']\n",
    "\n",
    "   # calculate conversion figures and rates and overall lift (the percentage difference in conversion rate between control and treatment versions)\n",
    "    control_converted = control_data.sum()\n",
    "    treatment_converted = treatment_data.sum()\n",
    "    control_non_converted = len(control_data) - control_converted\n",
    "    treatment_non_converted = len(treatment_data) - treatment_converted\n",
    "    control_conversion = round(control_data.sum() * 100/ len(control_data), 3)\n",
    "    treatment_conversion = round(treatment_data.sum() * 100/ len(treatment_data), 3)\n",
    "    lift = round((treatment_conversion - control_conversion) / control_conversion , 3)\n",
    "\n",
    "    # calculate posterior parameters with conversion rates\n",
    "    posterior_control = beta(prior_alpha + control_converted, prior_beta + control_non_converted)\n",
    "    posterior_treatment = beta(prior_alpha + treatment_converted, prior_beta + treatment_non_converted)\n",
    "\n",
    "    # sample from posteriors\n",
    "    control_samples = posterior_control.rvs(2000)\n",
    "    treatment_samples = posterior_treatment.rvs(2000)\n",
    "    probability = np.mean(treatment_samples > control_samples)\n",
    "\n",
    "    # calculate mean and variance of the posterior for control and treatment groups\n",
    "    (control_mu), (control_var) = posterior_control.stats()\n",
    "    (treatment_mu), (treatment_var) = posterior_treatment.stats()\n",
    "    lift_percentage = (treatment_samples - control_samples) / control_samples\n",
    "\n",
    "    if i == 2:\n",
    "        i = round((datetime.strptime(a_b_test[\"timestamp\"].max(), '%Y-%m-%d %H:%M:%S.%f') - datetime.strptime(a_b_test[\"timestamp\"].min(), '%Y-%m-%d %H:%M:%S.%f'))/ timedelta(weeks=1),2) - 1\n",
    "    else:\n",
    "        i = i+1\n",
    "\n",
    "    print(f\"\\nRunning the experiment for {i} weeks\",\"\\n\", f\"Probability that the treatment > control: {probability*100:.2f}%\",\"\\n\", f\"by this much lift: {lift*100:.2f}%\")\n",
    "    print(f\"Control Posterior: Mean: {control_mu:.3f}, Variance: {control_var:.8f}\") \n",
    "    print(f\"Treatment Posterior: Mean: {treatment_mu:.3f}, Variance: {treatment_var:.8f}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Treatment__: button changed colour from blue to green. No other changes to the webpage or it’s content.\n",
    "\n",
    "__Control__: no change to the webpage.\n",
    "\n",
    "__Conversion__: user clicked and proceeded to the Contact section of the webpage.\n",
    "\n",
    "We can conclude that __after 2.14 weeks of experiment__ the treatment conversion was greater than the control in only 256 out of 2,000 posterior samples. __There is a 12.80% probability that the treatment has a greater conversion rate than the control.__\n",
    "\n",
    "__The control had a greater conversion than the treatment in 1,744 out of 2,000 posterior samples.__ Furthermore, __the lift conversion is -1.4%.__ __The change in button colour__ actually had a __detrimental impact on users clicking it__, and proceeding to the Contact section of the webpage.\n",
    "\n",
    "__The variances in the results__ were very small at 0.00000102 and 0.00000101 for the control and treatment respectively. This means the distribution of 2,000 samples is __concentrated around the mean__. This gives __a greater confidence in the result.__ \n",
    "\n",
    "__The advice would be to not proceed with the change and to stop the experiment.__\n",
    "\n",
    "__In practice this conclusion could have been reached beforehand.__ This is one of the benefits of Bayesian testing as __you can continuously monitor your results.__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
